{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83Yf_NE6MNIK"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# **Libraries**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XIEZMepBgk9",
    "outputId": "f313f1bf-b462-4bcf-ee4e-fa1e16813bef"
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OC5eOiRj9cI8",
    "outputId": "877b4c54-755b-4eb9-f129-8b2bae3f6fc5"
   },
   "outputs": [],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xKrc-Xlup3c",
    "outputId": "9897d4da-93b1-4df7-ace3-9bb54e084c02"
   },
   "outputs": [],
   "source": [
    "pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccnLjr4687Xa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import contractions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import keras\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, SimpleRNN, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D,GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Flatten, Dense,Dropout\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKYDcYuwMTln"
   },
   "source": [
    "# Data Pre-**processing**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GknPUB1F-DwF",
    "outputId": "b6af8f2a-52f9-4334-cec6-78895c8a1abf"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADvwo2mY_N2Z",
    "outputId": "cd617bd3-adf1-4eb6-c353-1f8cb1d028d5"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueIh5Oep_Uoy"
   },
   "outputs": [],
   "source": [
    "data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5YJlEjb_VBB"
   },
   "outputs": [],
   "source": [
    "data.columns = [\"SpamHam\",\"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNQy8UQTED9L"
   },
   "outputs": [],
   "source": [
    "x=data['Tweet']\n",
    "y=data['SpamHam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d701KX6jEQrL",
    "outputId": "03cbc724-8c2e-43c5-ec60-87d2c438666d"
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "X6bhv4VHADH4",
    "outputId": "0537d121-e5a4-4b2b-a48c-dedb186ee8c6"
   },
   "outputs": [],
   "source": [
    "def word_count_plot(data):\n",
    "     # finding words along with count\n",
    "     word_counter = collections.Counter([word for sentence in data for word in sentence.split()])\n",
    "     most_count = word_counter.most_common(30) # 30 most common words\n",
    "     # sorted data frame\n",
    "     most_count = pd.DataFrame(most_count, columns=[\"Word\", \"Count\"]).sort_values(by=\"Count\")\n",
    "     most_count.plot.barh(x = \"Word\", y = \"Count\", color=\"green\", figsize=(10, 15))\n",
    "word_count_plot(data[\"Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efYL6mKKA3gC"
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "def preprocessing(data):\n",
    "      sms = contractions.fix(data) # converting shortened words to original (Eg:\"I'm\" to \"I am\")\n",
    "      sms = sms.lower() # lower casing the sms\n",
    "      sms = re.sub(r'https?://S+|www.S+', \"\", sms).strip() #removing url\n",
    "      sms = re.sub(\"[^a-z ]\", \"\", sms) # removing symbols and numbes\n",
    "      sms = sms.split() #splitting\n",
    "      # lemmatization and stopword removal\n",
    "      sms = [lem.lemmatize(word) for word in sms if not word in set(stopwords.words(\"english\"))]\n",
    "      sms = \" \".join(sms)\n",
    "      return sms\n",
    "x = data[\"Tweet\"].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ytKkS2-CJgP"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_enc = LabelEncoder()\n",
    "y = lb_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHtrRvc-NCTv"
   },
   "source": [
    "# **Tokenization of Message**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcBAd2dtCMpD"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() #initializing the tokenizer\n",
    "tokenizer.fit_on_texts(x)# fitting on the sms data\n",
    "text_to_sequence = tokenizer.texts_to_sequences(x) # creating the numerical sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O2eDFqfCN0L",
    "outputId": "2a797924-3335-433e-9abc-171dccae8264"
   },
   "outputs": [],
   "source": [
    " for i in range(5):\n",
    "           print(\"Text               : \",x[i] )\n",
    "           print(\"Numerical Sequence : \", text_to_sequence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8n3i19WACQ5B",
    "outputId": "42f0ddf8-927b-40cc-ce8f-47fe49b6486b"
   },
   "outputs": [],
   "source": [
    "tokenizer.index_word # this will output a dictionary of index and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-0qJ_X6CUWy",
    "outputId": "5d4b5841-7065-460a-81e1-b1110c089077"
   },
   "outputs": [],
   "source": [
    "max_length_sequence = max([len(i) for i in text_to_sequence])\n",
    " # finding the length of largest sequence\n",
    "X = pad_sequences(text_to_sequence, maxlen=max_length_sequence, \n",
    "                                    padding = \"pre\") \n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgihjk7fNOmp"
   },
   "source": [
    "# **Training and Testing Split**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjgSPkSZE49d"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=101, test_size= 0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq5aMiBWNU6E"
   },
   "source": [
    "# Model **LSTM**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BbTmU3DCYQB"
   },
   "outputs": [],
   "source": [
    "TOT_SIZE = len(tokenizer.word_index)+1\n",
    "def create_model():\n",
    "      lstm_model = Sequential()\n",
    "      lstm_model.add(Embedding(TOT_SIZE, 32, input_length=max_length_sequence)) #convert each word into a fixed length vector of defined size\n",
    "      lstm_model.add(LSTM(100))\n",
    "      lstm_model.add(Dropout(0.4))#to avoid overfitting #reduce the number of neurons\n",
    "      lstm_model.add(Dense(20, activation=\"relu\"))#to introduce non-linearity into the output of a neuron\n",
    "      lstm_model.add(Dropout(0.3))\n",
    "      lstm_model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      return lstm_model\n",
    "lstm_model = create_model()\n",
    "lstm_model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_Aj_UYHCbgV",
    "outputId": "9a952d71-6069-4d22-ff54-1cc893ec9a11"
   },
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMWhigqVCePp",
    "outputId": "136e58ad-f933-430d-99a6-8a4b3a78622a"
   },
   "outputs": [],
   "source": [
    "lstm_model.fit(X_train, y_train, epochs = 5, validation_split=0.2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sc4wjnHTDLvn",
    "outputId": "a7fe1c11-2c32-4a99-a44c-b6b5f75f34d5"
   },
   "outputs": [],
   "source": [
    "test_acc=lstm_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNYBVETSF_-k",
    "outputId": "4c1b1a7e-4c4c-484a-cb60-88a8b439f280"
   },
   "outputs": [],
   "source": [
    "print('accuracy for LSTM model is %.03f'%(test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwrmOIOPN-K5"
   },
   "source": [
    "# **Model Bidirectional LSTM**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TeF9XZGG3Uk"
   },
   "outputs": [],
   "source": [
    "TOT_SIZE = len(tokenizer.word_index)+1\n",
    "def create_model():\n",
    "    \n",
    "      bidirectional_lstm_model = Sequential()\n",
    "      bidirectional_lstm_model.add(Embedding(TOT_SIZE, 32, input_length=max_length_sequence))\n",
    "      bidirectional_lstm_model.add(Bidirectional(LSTM(64)))\n",
    "      bidirectional_lstm_model.add(Dropout(0.4))\n",
    "      bidirectional_lstm_model.add(Dense(20, activation=\"relu\")) #to introduce non-linearity into the output of a neuron.\n",
    "      bidirectional_lstm_model.add(Dropout(0.3))\n",
    "      bidirectional_lstm_model.add(Dense(1, activation = \"sigmoid\"))\n",
    "      return bidirectional_lstm_model\n",
    "bidirectional_lstm_model = create_model()\n",
    "bidirectional_lstm_model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilMSul-pHcsq",
    "outputId": "6d113f8a-7b8e-4a38-8abb-c4fe84e0bc61"
   },
   "outputs": [],
   "source": [
    "bidirectional_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BXJm9lKHxox",
    "outputId": "02cfb566-3571-4716-c422-761635820f11"
   },
   "outputs": [],
   "source": [
    "bidirectional_lstm_model.fit(X_train, y_train, epochs = 5, validation_split=0.2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFBY2s3yIA7o"
   },
   "outputs": [],
   "source": [
    "test_acc_bidirectional_lstm_model=bidirectional_lstm_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yabcve2AIDEK"
   },
   "outputs": [],
   "source": [
    "print('accuracy for bidirectional lstm model is %.03f'%(test_acc_bidirectional_lstm_model[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKi7kZDwOC9c"
   },
   "source": [
    "# **Model Dense Text Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxHaIZrlYwz4"
   },
   "outputs": [],
   "source": [
    "vocab_size = 500 # As defined earlier\n",
    "embeding_dim = 16\n",
    "drop_value = 0.2 # dropout\n",
    "n_dense = 21\n",
    "max_len = 50 \n",
    "trunc_type = \"post\" \n",
    "padding_type = \"post\" \n",
    "oov_tok = \"<OOV>\" \n",
    "vocab_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24g94yt3TWAy"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embeding_dim, input_length=max_len))#convert to vectors\n",
    "model.add(GlobalAveragePooling1D())#average pooling is done in order to smooth the flow of neurons and avoid overfitting \n",
    "model.add(Dense(24, activation='relu'))#to introduce non-linearity into the output of a neuron\n",
    "model.add(Dropout(drop_value))#how many neurons should be dropped to avoid overfiting\n",
    "model.add(Dense(1, activation='sigmoid'))#regular deeply connects neural network layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhgDzkcvZMfF"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqvAj2ASaDYH"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, char_level=False, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(x)\n",
    "training_sequences = tokenizer.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buksaB3GKs6t"
   },
   "outputs": [],
   "source": [
    "print(training_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmam6z4ca6tm"
   },
   "outputs": [],
   "source": [
    "training_padded = pad_sequences (training_sequences, maxlen = max_len, padding = padding_type, truncating = trunc_type )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4AorxxALEUz"
   },
   "outputs": [],
   "source": [
    "print(training_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsFmHeBlbf4S"
   },
   "outputs": [],
   "source": [
    "len(training_padded[0]), len(training_padded[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E4RCi8lLdh9"
   },
   "source": [
    "# **test and train split**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNnQCQBXcEUH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_padded,y,random_state=101, test_size= 0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twi7XxWVLjTg"
   },
   "source": [
    "# **Model**\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrFMQG6zUaqI"
   },
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "model.fit(X_train, y_train, epochs=num_epochs, validation_split=0.2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR_sEKVUVQvh"
   },
   "outputs": [],
   "source": [
    "test_acc=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mddHlVCDdkm_"
   },
   "outputs": [],
   "source": [
    "print('accuracy for DenseTextClassifier model is %.02f'%(test_acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cgihjk7fNOmp",
    "Cq5aMiBWNU6E",
    "IwrmOIOPN-K5",
    "WKi7kZDwOC9c",
    "8E4RCi8lLdh9",
    "Twi7XxWVLjTg"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
